import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
get_ipython().magic('matplotlib inline')

from sklearn.datasets import load_breast_cancer
cancer=load_breast_cancer()
cancer.keys()
print(cancer['DESCR'])
df=pd.DataFrame(cancer['data'],columns=cancer['feature_names'])
df.head()

from sklearn.cross_validation import train_test_split
x=df
y=cancer['target']
X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.30, random_state=101)

from sklearn.svm import SVC
model=SVC()
model.fit(X_train,y_train)
predict=model.predict(X_test)

from sklearn.metrics import classification_report,confusion_matrix
print(confusion_matrix(y_test,predict))
print('\n')
print(classification_report(y_test,predict))

#It can be seen that the class 0 predicted is 0. The data needs to be normalized 
#and the parameters of SVM needs to be adjusted.

#grid search
from sklearn.grid_search import GridSearchCV

#C value is the cost for misclassification. It penalizes the mis classified classes.
#This will decrease the bias but will increase variance. Low C cost will increase the bias but decrease the variance. 
#Hence the cost should be such that the bias and variance have a trade off
#small gamma is the gausian of large variance. High gamma will decrease variance and incraese bias

param_grid={'C':[0.1,1,10,100,100],'gamma':[1,0.1,0.01,0.001,0.0001]}
grid=GridSearchCV(SVC(),param_grid,verbose=3)

grid.fit(X_train,y_train)
grid.best_params_
grid_predict=grid.predict(X_test)
print(confusion_matrix(y_test,grid_predict))
print(classification_report(y_test,grid_predict))

import nltk
nltk.download_shell()
messages=[line.rstrip() for line in open('smsspamcollection/SMSSpamCollection')]
import os
os.getcwd()
print(len(messages))
messages.head(5)

for mess_no,message in enumerate(messages[:10]):
    print(mess_no,message)
    print('\n')

import string
from nltk.corpus import stopwords
def text_process(mess):
    """
    1.remove punc
    2.remove stop words
    3.return list of clean words
    
    """
    
    nopunc=[char for char in mess if char not in string.punctuation]
    nopunc=''.join(nopunc)
    return[word for word in nopunc.split() if word.lower() not in stopwords.words('english')]

messages['message'].head(5).apply(text_process)
from sklearn.feature_extraction.text import CountVectorizer
bow_transform=CountVectorizer(analyzer=text_process).fit(messages['message'])
mess4=messages['message'][3]
print(mess4)
bow4=bow_transform.transform([mess4])
print(bow4)
bow_transform.get_feature_names()[9554]
message_bow=bow_transformer.transform(messages['message'])
message_bow.nnz
from sklearn.feature_extraction.text import TfidfTransformer
tf_idf=TfidfTransformer().fit(message_bow)
tfidf4=tf_idf.transform(bow4)

#weights of words
print(tfidf4)
messages_tfidf=tf_idf.transform(message_bow)
from sklearn.naive_bayes import MultinomialNB
spam_detect_model=MultinomialNB().fit(messages_tfidf,messages['label'])
spam_detect_model.predict(tfidf4)[0]

from sklearn.pipeline import Pipeline
pipeline=Pipeline([
    ('bow',CountVectorizer(analyzer=text_process)),
    ('tfidf',TfidfTransformer()),
    ('Classifier',MultinomialNB())
])


pipeline.fit(msg_train,label_train)
predictions=pipeline.predict(msg_test)
#metrics

